{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b36fe48a",
   "metadata": {},
   "source": [
    "# Distribution Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34139a8",
   "metadata": {},
   "source": [
    "**Instructor:** Luisa Watkins, l1watkins@ucsd.edu (SPIESS 212)\n",
    "  \n",
    "**TA:** Kathryn Chen, ksc005@ucsd.edu\n",
    "\n",
    "Lecture notes inspired by Paul Siegel's ECE 250 course notes.\n",
    "\n",
    "Note: These are the full comprehensive notes, but the class will cover only the highlights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a427ad",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We just revewed basic probability and random variables. If we step back and think about the random variable $X$,we can define the probability measure $P_X$ for an event $E$ in the possible event space for $X$. I won't dive too deep into the theory here, but with probability measure $P_X(E)$, we can use existing axioms of probability to find $P_X(E)$ for any interval $-\\infty<a<b<\\infty$ :\n",
    "$$P_X(E) \\rightarrow P_X((a,b)), \\quad -\\infty<a<b<\\infty$$\n",
    "This is since a certain set of outcomes can give us the event $E$.\n",
    "\n",
    "It's enough to consider intervals of the form $(-\\infty,x], x \\in \\mathbb{R}$.\n",
    "\n",
    "This leads us to the...\n",
    "\n",
    "## Cumulative Distribution Function (CDF)\n",
    "\n",
    "for $x \\in \\mathbb{R}, F_X(x) = P_X((-\\infty,x])=P(X≤x)$\n",
    "\n",
    "### Properties of CDF\n",
    "\n",
    "1. $F_X(x) \\geq 0,  \\forall x \\in \\mathbb{R}$\n",
    "2. $F_X(x)$ is monotonically non-decreasing: $F_X(a) \\leq F_X(b)$ for $a < b$\n",
    "3. $lim_{x \\rightarrow -\\infty} F_x(x) = 0$; $lim_{x \\rightarrow \\infty} F_x(x) = 1$\n",
    "4. $F_X(a^{+}) = lim_{x \\rightarrow a^{+}} F_X(x) = F_X(a)$\n",
    "5. $P(X=a) = F_X(a^{+}) - F_X(a^{-})$, $F_X(a^{-}) = lim_{x \\rightarrow a^{-}} F_X(x)$\n",
    "\n",
    "**Example:** Flip a biased coin, with $P(0)=1-p$, $P(1)=p$. Let $X$ be the value of the flip. The CDF $F_x(x)$ is \n",
    "$$F_x(x) = \\begin{cases}\n",
    "0,& x<0\\\\\n",
    "1-p,& 0≤x<1\\\\\n",
    "1,& x≥1\n",
    "\\end{cases}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056f517e",
   "metadata": {},
   "source": [
    "## Discrete Random Variable\n",
    "\n",
    "The random variable $X$ is **discrete** if the CDF consists of steps at a countable set of numbers, denoted $\\mathscr{X}$, as in the last example:\n",
    "$$p_X(x)=P(X=x), \\quad x \\in \\mathscr{X}$$\n",
    "determines $\\mathscr{X}$ completely, where we call $p_X(x)$ the **probability mass function (PMF).** The relationship with the CDF is then:\n",
    "$$F_X(x)= \\sum_{x_k \\in \\mathscr{X}} p_X(x_k)u(x-x_k)$$\n",
    "where $u(x)= \\begin{cases}\n",
    "0,& x<0\\\\\n",
    "1,& x≥0\n",
    "\\end{cases}$\n",
    "is the unit step function.\n",
    "\n",
    "** examples found in handout! **\n",
    "\n",
    "## Continuous Random Variable\n",
    "\n",
    "For our purposes, we will focus on the **continuous** random variable $X$, which has a continuous CDF $F_X(x)$. Then the CDF can be expressed as\n",
    "$$F_X(x)= \\int_{-\\infty}^x f_X(u)du$$\n",
    "where $f_X(x) is the **probability density function (PDF)**, which was covered in the last section.\n",
    "\n",
    "If $F_X(x)$ is everywhere differentiable, then\n",
    "$f_X(x) = \\frac{d}{dx} F_X{x} = lim_{\\delta x \\rightarrow 0} \\frac{F(x + \\delta x) - F(x)}{\\delta x} = lim_{\\delta x \\rightarrow 0} \\frac{P(x < X \\leq x + \\delta x)}{\\delta x}$\n",
    "\n",
    "** examples found in handout! **\n",
    "\n",
    "### Properties of the PDF\n",
    "1. $f_X(x) \\geq 0, \\forall x \\in \\mathbb{R}$\n",
    "2. $\\int_{-\\infty}^{\\infty} f_X(x) = 1$\n",
    "3. for any event $A \\subset \\mathbb{R}, P(X \\in A) = \\int_{X \\in A} f_X(x) dx$\n",
    "\n",
    "$P(a < X \\leq b) = P(a < X < b) = P(a \\leq X < b) = P(a \\leq X \\leq b) = \\int_a^b f_X(x) dx$\n",
    "\n",
    "**Example:**  \n",
    "$X \\sim unif[a,b], a < b$ (uniform random variable!)\n",
    "\n",
    "$$F_x(x) = \\begin{cases}\n",
    "0,& x<a\\\\\n",
    "\\frac{x-a}{b-a},& a≤x<b\\\\\n",
    "1,& x≥b\n",
    "\\end{cases}$$\n",
    "\n",
    "$$f_x(x) = \\begin{cases}\n",
    "0,& x<a\\\\\n",
    "\\frac{1}{b-a},& a≤x<b\\\\\n",
    "0,& x≥b\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2780030",
   "metadata": {},
   "source": [
    "## Expected Value\n",
    "\n",
    "We can also analyze a random variable $X$ by finding its \"average value\", or **expected value** $E[X]$.\n",
    "\n",
    "For a discrete random variable $(X \\sim p_X(x))$,\n",
    "$$E[X] = \\sum_{x \\in \\mathscr{X}} x p_X(x)$$\n",
    "\n",
    "For a continuous random variable $(X \\sim f_X(x))$,\n",
    "$$E[X] = \\int_{-\\infty}^{\\infty} x f_X(x) dx$$\n",
    "\n",
    "Note: If $f_X(x)$ is symmetric about $x=m$, then $E[X]=m$.\n",
    "\n",
    "## The Fundamental Theorem of Expectation\n",
    "### Discrete: \n",
    "$X \\sim p_X(x), Y \\sim g(X) \\sim p_Y(y)$,\n",
    "\n",
    "$$E[Y] = \\sum_{y \\in \\mathscr{Y}} y p_Y(y) = \\sum_{x \\in \\mathscr{X}} g(x) p_X(x) = E[g(X)]$$\n",
    "\n",
    "### Continuous:\n",
    "$X \\sim f_X(x), Y \\sim g(X) \\sim f_Y(y)$,\n",
    "$$E[Y] = \\int_{-\\infty}^{\\infty} y f_Y(y) dy = \\int_{-\\infty}^{\\infty} g(x) f_X(x) dx = E[g(X)]$$\n",
    "\n",
    "## Properties of Expectation\n",
    "1. if $g(x) \\geq 0$, with respect to $1$, then $E[g(X)] \\geq 0$\n",
    "2. constant function: $g(x) = c \\rightarrow E[c] = c$\n",
    "3. scalable: $g(x) = cx \\rightarrow E[cX] = cE[x]$\n",
    "4. additive: $g(x) = g_1(x) + g_2(x) \\rightarrow E[g(X)] = E[g_1(X) + g_2(X)] = E[g_1(X)]+ E[g_2(X)]$ \n",
    "\n",
    "3 & 4 use linearity of expectation!!\n",
    "\n",
    "## Second Moment\n",
    "\n",
    "### Discrete: \n",
    "$$E[X^2] = \\sum_{x \\in \\mathscr{X}} x^2 p_X(x)$$\n",
    "\n",
    "### Continuous:\n",
    "$$E[X^2] = \\int_{-\\infty}^{\\infty} x^2 f_X(x)$$\n",
    "\n",
    "## Variance:\n",
    "$$var(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2$$\n",
    "\n",
    "** examples in handout! **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f8143",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "[Download Exercises](https://drive.google.com/file/d/18lu0KqN2Jg5bxpBytKS2ZEA3NGep-Ynn/view?usp=sharing)\n",
    "\n",
    "![Exercise1](../_static/DistributionFunctionsExercises2025)\n",
    "\n",
    "![Exercise2](../_static/page2DistributionFunctionsExercises2025)\n",
    "\n",
    "![Exercise3](../_static/page3DistributionFunctionsExercises2025)\n",
    "\n",
    "\n",
    "# Handout\n",
    "\n",
    "[Download Handout](https://drive.google.com/file/d/1qm-HJji6EVDR-OVoef6aZFkWOQOpfFB0/view?usp=sharing)\n",
    "\n",
    "![Handout1](../_static/DistributionFunctionsHandout2025)\n",
    "\n",
    "![Handout2](../_static/page2DistributionFunctionsHandout2025)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
